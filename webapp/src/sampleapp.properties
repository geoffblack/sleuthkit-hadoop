#list of valid credentials (comma-separated)
credentials=admin@admin123,texaspete@texaspete123
#the initial directory path on the server where user will start to select a disk image file
files.dir.path=/usr/local/hadoop
#command script to execute on the server (Usage: tpkickoff.sh <job name> <selected image file> <pipeline_jar_dir>)
command.script=/usr/local/hadoop/tpkickoff.sh
#pipeline_jar_dir argument for command to execute on the server (Usage: tpkickoff.sh <job name> <selected image file> <pipeline_jar_dir>)
command.jar=/usr/local/hadoop/pipeline
#HDFS path for report ($hash means hash of disk image)
report.hdfs.pattern=/texaspete/data/$hash/reports.zip
#URL for hadoop webservice to download a file in HDFS, $file means file to download (replace each / in file path with %2F first)
#report.ws.pattern=http://localhost:50075/streamFile?filename=$file&delegation=null
report.ws.pattern=file:///texaspete/data/$hash/$file
#path (make sure $PATH includes path to fsrip.)
command.path=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/hadoop/apache-maven/bin:/usr/local/hadoop/fsrip/build/src
#set command working directory
command.work_dir=/usr/local/hadoop
#set $LD_LIBRARY_PATH (for fsrip)
command.fsrip.lib=/usr/local/hadoop/fsrip/deps/lib
#set hadoop home (set $HADOOP_HOME)
command.hadoop.home=/usr/lib/hadoop
#column names for the "job monitor" page (comma-separated)
columns=job name,image id,current task,task status,time started,task map progress,task reduce progress
#local path on the server for "report link" ($hash means hash of disk image). [NO LONGER USED]
#report.local.pattern=
